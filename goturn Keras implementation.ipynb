{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies:\n",
    "\n",
    "- CUDA 9.0\n",
    "- cuDNN 7.4\n",
    "- Tensorflow-gpu 1.12.0\n",
    "- Keras 2.2.4\n",
    "- pillow 5.4\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fileutil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fileutil.py\n",
    "\n",
    "Utilities for various file operations\n",
    "'''\n",
    "\n",
    "import glob, os\n",
    "import numpy as np\n",
    "\n",
    "def makeFullExtensionList(ext_list:list):\n",
    "    '''\n",
    "Create both uppercase and lowercase extension lists without duplication\n",
    "    \n",
    "     args:\n",
    "         ext_list: list of extensions\n",
    "\n",
    "     returns:\n",
    "         Extension list with unique and extended case\n",
    "    '''\n",
    "    temp_set = set(ext_list)\n",
    "    res_list = []\n",
    "    for ext in temp_set:\n",
    "        # Ignore it is empty\n",
    "        if len(ext) == 0:\n",
    "            continue\n",
    "        # If there is no., Add it to the beginning\n",
    "        if ext[0] is not '.':\n",
    "            ext = '.' + ext\n",
    "        res_list.append(ext.lower())\n",
    "        res_list.append(ext.upper())\n",
    "    return res_list\n",
    "\n",
    "def getTargetPathList(search_root, ext_list = ['.xml']):\n",
    "    '''\n",
    "Get list of paths to files with specified extension\n",
    "     args:\n",
    "         search_root: search target root path\n",
    "         ext_list: Extension of file to be searched\n",
    "     returns:\n",
    "         Search root path, list of paths relative to search root path\n",
    "    '''\n",
    "    res_root = None # Search output root path\n",
    "    res_list = [] # File path list relative to search root \n",
    "    target_exts = makeFullExtensionList(ext_list)\n",
    "    if len(target_exts) == 0:\n",
    "        return res_root, res_list\n",
    "    # Create target file relative path list\n",
    "    res_root = os.path.abspath(search_root)\n",
    "    curr_dir = os.getcwd() # Save current path\n",
    "    os.chdir(search_root) # Move to search target route\n",
    "    for ext in target_exts:\n",
    "        res_list += glob.glob('**/*' + ext, recursive=True)\n",
    "    os.chdir(curr_dir) # Return to the original\n",
    "    return res_root, sorted(res_list)\n",
    "\n",
    "class ODData(object):\n",
    "    '''\n",
    "    Object Detection Data Class    \n",
    "\n",
    "   '''\n",
    "    def __init__(self, img_path:str, size, bboxes, classes):\n",
    "        self.img_path = img_path\n",
    "        self.size = size\n",
    "        self.bboxes = bboxes\n",
    "        self.classes = classes\n",
    "        self.num = len(bboxes)\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Votutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility for reading data in VOT Challenge format\n",
    "\n",
    "import os, csv\n",
    "from random import shuffle\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "from tools import fileutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTrainValidDirList(mov_root:str, train_rate:float=0.8,\n",
    "    train_list_name:str='list_train.txt', valid_list_name:str='list_valid.txt'):\n",
    "    '''\n",
    "    Create distribution list for image frame directory\n",
    "     args:\n",
    "         mov_root: Root directory where frame image directories are stored\n",
    "         train_rate: Rate used for inner learning (0.0-1.0))\n",
    "    '''\n",
    "    mov_dirs = []\n",
    "    for x in os.scandir(mov_root):\n",
    "        if x.is_dir() is True:\n",
    "            mov_dirs.append(x.name)\n",
    "    mov_dirs = ['{}\\n'.format(x) for x in mov_dirs] #Line feed addition\n",
    "    shuffle(mov_dirs)\n",
    "    train_num = int(len(mov_dirs) * train_rate)\n",
    "    train_list = mov_dirs[:train_num]\n",
    "    valid_list = mov_dirs[train_num:]\n",
    "    train_list.sort()\n",
    "    valid_list.sort()\n",
    "    # Write to file\n",
    "    with open(os.path.join(mov_root, train_list_name), 'w') as f:\n",
    "        f.writelines(train_list)\n",
    "    with open(os.path.join(mov_root, valid_list_name), 'w') as f:\n",
    "        f.writelines(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovDirList(mov_root:str, target_list=None):\n",
    "    '''\n",
    "    Acquisition of image frame directory list\n",
    "     args:\n",
    "         mov_root: Root directory where frame image directories are stored \\ n\n",
    "         target_list: Path to target image directory name list file \\ n\n",
    "     returns:\n",
    "         List of image frame directory paths\n",
    "    '''\n",
    "    mov_dirs = []\n",
    "    if target_list is None:\n",
    "        # If not specified, target all directories immediately below\n",
    "        for x in os.scandir(mov_root):\n",
    "            if x.is_dir() is True:\n",
    "                mov_dirs.append(x.name)\n",
    "    else:\n",
    "        with open(os.path.join(mov_root, target_list)) as f:\n",
    "            rows = f.readlines()\n",
    "            for x in rows:\n",
    "                mov_dirs.append(x.rstrip()) \n",
    "    return mov_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOTBoxData(object):\n",
    "    '''\n",
    "    VOT Challenge Single Tracking format data class\n",
    "     However, polygon vertex information is converted to circumscribed rectangles\n",
    "     args:\n",
    "         img_path: Path to the target image\n",
    "         points: Vertex list of target object (pixel unit)\n",
    "    '''\n",
    "    def __init__(self, img_path:str, points:Tuple[float]):\n",
    "        self.img_path = img_path\n",
    "        temp = np.array(points).reshape((-1,2))\n",
    "        x_min, y_min = np.min(temp, axis=0)\n",
    "        x_max, y_max = np.max(temp, axis=0)\n",
    "        self.bbox = (x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeBBox(bbox, search_area):\n",
    "    '''BoundeingBox encoding \n",
    "     (x_min, y_min, x_max, y_max) [pixel] format \n",
    "     Convert to (cx, cy, w, h) (ratio to search_area) format \n",
    "     args:\n",
    "         bbox: Source BoundingBox \n",
    "         search_area: Object search area \n",
    "    '''\n",
    "    # Convert expression format\n",
    "    cx = (bbox[0] + bbox[2]) * 0.5\n",
    "    cy = (bbox[1] + bbox[3]) * 0.5\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    # convert to earch_areas relative value\n",
    "    s_w = search_area[2] - search_area[0]\n",
    "    s_h = search_area[3] - search_area[1]\n",
    "    cx = (cx - search_area[0]) / s_w\n",
    "    cy = (cy - search_area[1]) / s_h\n",
    "    w /= s_w\n",
    "    h /= s_h\n",
    "    return (cx, cy, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeBBox(bbox, search_area):\n",
    "    '''BoundeingBox decoding \n",
    "     (cx, cy, w, h) (ratio to search_area) form \n",
    "     (x_min, y_min, x_max, y_max) Converted to [pixel] format\n",
    "     args:\n",
    "         bbox: Source BoundingBox\n",
    "         search_area: Object search area\n",
    "    '''\n",
    "    # search_areas relative value â†’ pixel conversion\n",
    "    s_w = search_area[2] - search_area[0]\n",
    "    s_h = search_area[3] - search_area[1]\n",
    "    cx = bbox[0] * s_w + search_area[0]\n",
    "    cy = bbox[1] * s_h + search_area[1]\n",
    "    w = bbox[2] * s_w\n",
    "    h = bbox[3] * s_h\n",
    "    # Convert expression format\n",
    "    x_min = cx - 0.5 * w\n",
    "    y_min = cy - 0.5 * h\n",
    "    x_max = cx + 0.5 * w\n",
    "    y_max = cy + 0.5 * h\n",
    "    return (x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSearchArea(bbox, img_size, search_rate=0.8):\n",
    "    '''Calculation of search range\n",
    "     args:\n",
    "         bbox: target bbxo \n",
    "         img_size: Target image (whole) size \n",
    "         search_range: Search radius magnification\n",
    "    '''\n",
    "    width, height = img_size\n",
    "    # Based on diagonal length\n",
    "    w = (bbox[2] - bbox[0])\n",
    "    h = (bbox[3] - bbox[1])\n",
    "    cx = (bbox[0] + bbox[2]) * 0.5\n",
    "    cy = (bbox[1] + bbox[3]) * 0.5\n",
    "    search_rad = np.sqrt(w**2 + h**2) * search_rate\n",
    "    # Determine crop range\n",
    "    crop_area = [cx - search_rad, cy - search_rad, cx + search_rad, cy + search_rad]\n",
    "    # If it protrudes (sobresalir), move it inward\n",
    "    offset_x = 0.0\n",
    "    if crop_area[0] < 0.0:\n",
    "        offset_x = -crop_area[0]\n",
    "    elif crop_area[2] > width:\n",
    "        offset_x = width - crop_area[2]\n",
    "    crop_area[0] = int(crop_area[0] + offset_x)\n",
    "    crop_area[2] = int(crop_area[2] + offset_x)\n",
    "    offset_y = 0.0\n",
    "    if crop_area[1] < 0.0:\n",
    "        offset_y = -crop_area[1]\n",
    "    elif crop_area[3] > height:\n",
    "        offset_y = height - crop_area[3]\n",
    "    crop_area[1] += int(crop_area[1] + offset_y)\n",
    "    crop_area[3] += int(crop_area[3] + offset_y)\n",
    "    # Crop if protruding\n",
    "    if crop_area[0] < 0:\n",
    "        crop_area[0] = 0\n",
    "    if crop_area[2] > width:\n",
    "        crop_area[2] = width\n",
    "    if crop_area[1] < 0:\n",
    "        crop_area[1] = 0\n",
    "    if crop_area[3] > height:\n",
    "        crop_area[3] = height\n",
    "    return crop_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTrainInput(tgt:VOTBoxData, search:VOTBoxData, input_size=(224, 224)):\n",
    "    '''Input for learning and creation of correct answer data\n",
    "     args:\n",
    "         tgt: Detection data of the detection target\n",
    "         search: Detection data of search results\n",
    "     returns:\n",
    "         Detection target image (numpy array), search target image (numpy array), correct answer bbox\n",
    "    '''\n",
    "    # Loading images\n",
    "    img_tgt = Image.open(tgt.img_path)\n",
    "    img_search = Image.open(search.img_path)\n",
    "    # Calculation of search range\n",
    "    search_area = calcSearchArea(tgt.bbox, img_tgt.size)\n",
    "    # Creating correct answer data ((cx, cy, w, h) format)\n",
    "    bbox_gt = encodeBBox(tgt.bbox, search_area)\n",
    "    # Creating an image\n",
    "    img_tgt = img_tgt.crop(search_area).resize(input_size)\n",
    "    img_search = img_search.crop(search_area).resize(input_size)\n",
    "    img_tgt = (np.array(img_tgt) / 128.0) - 1.0\n",
    "    img_search = (np.array(img_search) / 128.0) - 1.0\n",
    "    return img_tgt, img_search, bbox_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePredictInput(img_tgt:str, bbox_tgt, img_search:str, input_size=(224, 224)):\n",
    "    '''Create inference input data\n",
    "     args:\n",
    "         img_tgt: Image to be detected (PIL Image)\n",
    "         bbox_tgt: bbox representing the object to be detected\n",
    "         img_search: Search target image (PIL Image)\n",
    "     returns:\n",
    "         Network input, search range bbox\n",
    "    '''\n",
    "    # Calculation of search range\n",
    "    search_area = calcSearchArea(bbox_tgt, img_tgt.size)\n",
    "    # Creating an image\n",
    "    img_tgt = img_tgt.crop(search_area).resize(input_size)\n",
    "    img_search = img_search.crop(search_area).resize(input_size)\n",
    "    img_tgt = (np.array(img_tgt) / 128.0) - 1.0\n",
    "    img_search = (np.array(img_search) / 128.0) - 1.0\n",
    "    return [np.array([img_tgt]), np.array([img_search])], search_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVOTDir(mov_dir, img_ext='.jpg')->List[VOTBoxData]:\n",
    "    '''\n",
    "    args:\n",
    "         mov_dir: frame image directory path\n",
    "         img_ext: Extension of frame image\n",
    "     returns:\n",
    "         List of VOTBoxData\n",
    "    '''\n",
    "    # Get list of images under specified directory\n",
    "    img_dir, img_path_list = fileutil.getTargetPathList(mov_dir, ext_list=[img_ext])\n",
    "    img_path_list.sort()\n",
    "    res = []\n",
    "    with open(os.path.join(img_dir, 'groundtruth.txt')) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            img_path = os.path.join(img_dir, img_path_list[i]) # Create image path\n",
    "            points = np.array(row, dtype=np.float).reshape((-1,2)) #Target polygon vertex list\n",
    "            res.append(VOTBoxData(img_path, points))\n",
    "    return res\n",
    "\n",
    "def pickDiffPairIndices(input, diff_list=(-2, -1, 0, 1, 2), sample_per_diff=None):\n",
    "    '''\n",
    "    Generate an index list that randomly picks up a specified difference pair\n",
    "     args:\n",
    "         input: list or list length \\ n\n",
    "         diff_list: a list of diffs of the index on the list of elements to pair \\ n\n",
    "         sample_per_diff: How many sample pairs to get for one difference. If None, up to the upper limit\n",
    "    '''\n",
    "    input_len = len(input) if type(input) == list else input # Get the total number of elements\n",
    "    sample_num = sample_per_diff if sample_per_diff is not None else input_len\n",
    "    res_list = [] # Output list\n",
    "    for diff in diff_list:\n",
    "        indices = [x for x in range(input_len)]\n",
    "        if diff < 0:\n",
    "            indices = indices[-diff:] # If diff is negative, round up the lower index limit\n",
    "        elif diff > 0:\n",
    "            indices = indices[:-diff] # If diff is positive, lower the upper limit of the index\n",
    "        # Randomly extract up to sample_num items\n",
    "        shuffle(indices)\n",
    "        for x in indices[:sample_num]:\n",
    "            res_list.append((x, x + diff)) # xth and x + diffth pairs\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOTTrainGenerator(Sequence):\n",
    "    '''\n",
    "    VOT Challenge Single Tracking learning data generator\n",
    "    '''\n",
    "    def __init__(self, mov_root:str, target_list=None, input_shape = (224,224,3), diff_list=(-1, 1), batch_size=32):\n",
    "        '''\n",
    "        args:\n",
    "            mov_root: Root path for storing frame image directories\n",
    "            target_list: Directory list file handled by the generator. If None, target all directories immediately below \\ n\n",
    "            input_shape: shape of input tensor to model\n",
    "            batch_size: Batch size\n",
    "        '''\n",
    "        self.mov_root = mov_root # Frame image directory group storage route\n",
    "        self.mov_dirs = getMovDirList(mov_root, target_list) # Get list of frame image directory\n",
    "        self.img_size = (input_shape[1], input_shape[0]) # Input image size (Width, Height) [pixel]\n",
    "        self.batch_size = batch_size # Batch size\n",
    "        self.diff_list = diff_list # Difference set list\n",
    "        self.makeTrainSamples() # Training sample creation\n",
    "\n",
    "    def makeTrainSamples(self):\n",
    "        '''\n",
    "        Creating training samples\n",
    "        '''\n",
    "        self.samples = []\n",
    "        for mov_dir in self.mov_dirs:\n",
    "            detect_res = readVOTDir(os.path.join(self.mov_root, mov_dir)) # Acquisition of set of target video frame and detection result\n",
    "            id_pairs = pickDiffPairIndices(detect_res, diff_list = self.diff_list) # Get index and pair for pickup\n",
    "            for id_pair in id_pairs:\n",
    "                x = detect_res[id_pair[0]]\n",
    "                y = detect_res[id_pair[1]]\n",
    "                sample = {'tgt': x, 'search':y }\n",
    "                self.samples.append(sample)\n",
    "        # Update size information\n",
    "        self.sample_num = len(self.samples)\n",
    "        self.batch_num = (len(self.samples) - 1) // self.batch_size + 1\n",
    "        shuffle(self.samples) # Random shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Batch number'''\n",
    "        return self.batch_num\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        '''Processing at end of epoch'''\n",
    "        self.makeTrainSamples() # Training sample creation\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Get batch data\n",
    "         args:\n",
    "             idx: batch index\n",
    "         return:\n",
    "             imgs: reference frame image list, search target frame list\n",
    "             results: Correct answer bbox (relative definition with the width and height of the search range phase set to 1.0)\n",
    "        '''\n",
    "        start_pos = self.batch_size * idx\n",
    "        end_pos = start_pos + self.batch_size\n",
    "        if end_pos > self.sample_num:\n",
    "            end_pos = self.sample_num\n",
    "        batch_items = self.samples[start_pos : end_pos]\n",
    "        # Creating batch content\n",
    "        x_tgt = []\n",
    "        x_search = []\n",
    "        y = []\n",
    "        for item in batch_items:\n",
    "            img_tgt, img_search, bbox_gt = makeTrainInput(item['tgt'], item['search'], self.img_size)\n",
    "            x_tgt.append(img_tgt)\n",
    "            x_search.append(img_search)\n",
    "            y.append(bbox_gt)\n",
    "        x_tgt = np.array(x_tgt) \n",
    "        x_search = np.array(x_search) \n",
    "        y = np.array(y) \n",
    "        return [x_tgt, x_search], y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tgt_dir = '/media/bodyscrap/drive_d/Dataset/vot2016'\n",
    "    gen = VOTTrainGenerator(tgt_dir, target_list='list_valid.txt')\n",
    "    num = len(gen)\n",
    "    for i in range(num):\n",
    "        print('{0}/{1}'.format(i + 1, num))\n",
    "        gen.__getitem__(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Dense, Flatten, BatchNormalization, Activation\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.engine.network import Network\n",
    "import numpy as np\n",
    "\n",
    "class Tracknet(object): \n",
    "    '''\n",
    "    GOTURN Network\n",
    "     The original feature extractor is AlexNet, \n",
    "     Converting Caffe's weight was troublesome,\n",
    "     It has been rewritten to use the appropriate network of keras.applications.\n",
    "    '''\n",
    "    def __init__(self, input_shape = (224,224,3)):\n",
    "        self.input_shape = input_shape # The size of the input image. Match the feature extractor used.\n",
    "\n",
    "    def build(self):\n",
    "        self.input_tgt = Input(self.input_shape)    # Image to be detected\n",
    "        self.input_search = Input(self.input_shape) # Search target image\n",
    "        # Share the same feature extractor\n",
    "        x_in = Input(self.input_shape)\n",
    "        feature_net = MobileNetV2(input_tensor=x_in, alpha=1.0, include_top=False)\n",
    "        for temp in feature_net.layers:\n",
    "            temp.trainable = False\n",
    "        feature_net = Network(x_in, feature_net.output, name='feature')\n",
    "        self.feature_tgt = feature_net(self.input_tgt)\n",
    "        self.feature_search = feature_net(self.input_search)\n",
    "        # Concatenate output results\n",
    "        self.concat = concatenate([self.feature_tgt, self.feature_search], axis = 3)\n",
    "        self.fc0 = Flatten()(self.concat)\n",
    "        # Full join (Original from (4096,) x 3 to (4,) at the end, but reduced because it did not fit in memory\n",
    "        x = Dense(1024)(self.fc0)\n",
    "        x = BatchNormalization()(x)\n",
    "        self.fc1 = Activation('relu')(x)\n",
    "        x = Dense(1024)(self.fc1)\n",
    "        x = BatchNormalization()(x)\n",
    "        self.fc2 = Activation('relu')(x)\n",
    "        x = Dense(1024)(self.fc2)\n",
    "        x = BatchNormalization()(x)\n",
    "        self.fc3 = Activation('relu')(x)\n",
    "        self.output = Dense(4)(self.fc3)\n",
    "        # Model output\n",
    "        self.model = Model(inputs=[self.input_tgt, self.input_search], outputs=self.output)\n",
    "        return self.model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tracknet = Tracknet()\n",
    "    model = tracknet.build()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, multiprocessing\n",
    "import glob\n",
    "from goturn_net import Tracknet\n",
    "from tools.votutil import VOTTrainGenerator\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Number of concurrently running processe\n",
    "    proc_count = multiprocessing.cpu_count() - 1\n",
    "    # Image generator initialization\n",
    "    img_root = '/media/bodyscrap/drive_d/Dataset/vot2016'\n",
    "    gen_train = VOTTrainGenerator(img_root, target_list='list_train.txt', batch_size=64)\n",
    "    gen_valid = VOTTrainGenerator(img_root, target_list='list_valid.txt', batch_size=64)\n",
    "    # Model initialization\n",
    "    model_dir = 'models'\n",
    "    model_name = 'model_goturn'\n",
    "    models = glob.glob(model_dir + '/' + model_name + '*.h5')\n",
    "    train_epochs = 100\n",
    "    initial_epoch = 0\n",
    "    if len(models) == 0:\n",
    "        net = Tracknet()\n",
    "        model = net.build()\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    else:\n",
    "        models.sort()\n",
    "        path_last_model = models[-1] # Final model Path\n",
    "        model = load_model(path_last_model, compile=True, custom_objects={'Network':Network})\n",
    "        cnt_start = path_last_model.rfind('_') + 1\n",
    "        cnt_end = path_last_model.rfind('.')\n",
    "        initial_epoch = int(path_last_model[cnt_start:cnt_end])\n",
    "    final_epoch = initial_epoch + train_epochs\n",
    "    model.fit_generator(gen_train, validation_data=gen_valid,\n",
    "    initial_epoch=initial_epoch, epochs=final_epoch, workers=proc_count)\n",
    "    # Save model\n",
    "    path_save = '{0}/{1}_{2:08}.h5'.format(model_dir, model_name, final_epoch)\n",
    "    model.save(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict file\n",
    "\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.applications import mobilenetv2\n",
    "from keras.engine.network import Network\n",
    "from tools.votutil import readVOTDir, makePredictInput, decodeBBox\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def drawBBox(img_org:Image, bboxes=[], colors=[(0, 255, 0), (255, 0, 0), (0, 0, 255)])->Image:\n",
    "    '''\n",
    "    Create image drawing BoundingBox \\ n\n",
    "     args:\n",
    "         img_org: Original image to be drawn \\ n\n",
    "         bboxes: List of BoundingBox \\ n\n",
    "         colors: BoundingBox drawing color list (tour) \\ n\n",
    "     returns:\n",
    "         Image in which BoundingBox is drawn in the input order (PIL.Image)\n",
    "    '''\n",
    "    img = img_org.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        box_draw = [int(x) for x in bbox] # Integerization\n",
    "        color_draw= colors[i % len(colors)]\n",
    "        draw.rectangle(box_draw, outline=color_draw)\n",
    "    return img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Target video directory\n",
    "    mov_dir = '/media/bodyscrap/drive_d/Dataset/vot2016/fish4'\n",
    "    # Loading the model\n",
    "    model_path = 'model_goturn.h5'\n",
    "    model = load_model(model_path, compile=False, custom_objects={'Network':Network})\n",
    "    model.summary()\n",
    "    # å‹•Read picture frame directory\n",
    "    frames = readVOTDir(mov_dir)\n",
    "    indices = [x for x in range(1, len(frames))] # Index after the first frame\n",
    "    res_root = '/media/bodyscrap/drive_d/goturn/GOTURN-Keras/result'\n",
    "    res_dir = os.path.join(res_root, os.path.basename(mov_dir))\n",
    "    os.makedirs(res_dir, exist_ok=True)\n",
    "    #Drawing of frame 0 (correct BoundingBox only)\n",
    "    img = Image.open(frames[0].img_path)\n",
    "    img = drawBBox(img, bboxes=[frames[0].bbox])\n",
    "    path_save = os.path.join(res_dir, os.path.basename(frames[0].img_path))\n",
    "    img.save(path_save)\n",
    "    # Drawing after the first frame (correct BoundingBox + estimated BoundingBox) \n",
    "    for idx in indices:\n",
    "        # Read input data\n",
    "        img_tgt = Image.open(frames[idx -1].img_path)\n",
    "        bbox_tgt = frames[idx -1].bbox\n",
    "        img_search = Image.open(frames[idx].img_path)\n",
    "        input_data, search_area = makePredictInput(img_tgt, bbox_tgt, img_search)\n",
    "        result = model.predict(input_data)\n",
    "        if result is None or len(result) == 0:\n",
    "            continue\n",
    "        res_box = decodeBBox(result[0], search_area)\n",
    "        img = drawBBox(img_search, bboxes=[frames[idx].bbox, res_box])\n",
    "        path_save = os.path.join(res_dir, os.path.basename(frames[idx].img_path))\n",
    "        img.save(path_save)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
