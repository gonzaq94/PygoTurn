{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# necessary imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "# import model\n",
    "# from torchsummary import summary\n",
    "\n",
    "# from datasets import ALOVDataset, ILSVRC2014_DET_Dataset\n",
    "from helper import (Rescale, shift_crop_training_sample,crop_sample, NormalizeToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "input_size = 224\n",
    "kSaveModel = 20000  # save model after every 20000 steps\n",
    "batchSize = 50  # number of samples in a batch\n",
    "kGeneratedExamplesPerImage = 10  # generate 10 synthetic samples per image\n",
    "transform = NormalizeToTensor()\n",
    "bb_params = {}\n",
    "enable_tensorboard = False\n",
    "if enable_tensorboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "args = None\n",
    "parser = argparse.ArgumentParser(description='GOTURN Training')\n",
    "num_batches=500000\n",
    "lr=1e-5\n",
    "gamma=0.1\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_decay_step=100000\n",
    "d='../data/'\n",
    "s='../saved_checkpoints/exp3/'\n",
    "lshift=5\n",
    "lscale=15\n",
    "minsc=-0.4\n",
    "maxsc=0.4\n",
    "seed=800\n",
    "resume=''\n",
    "b=50\n",
    "save_freq=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GoNet(nn.Module):\n",
    "    \"\"\" Neural Network class\n",
    "        Two stream model:\n",
    "        ________\n",
    "       |        | conv layers              Untrained Fully\n",
    "       |Previous|------------------>|      Connected Layers\n",
    "       | frame  |                   |    ___     ___     ___\n",
    "       |________|                   |   |   |   |   |   |   |   fc4\n",
    "                   Pretrained       |   |   |   |   |   |   |    * (left)\n",
    "                   CaffeNet         |-->|fc1|-->|fc2|-->|fc3|--> * (top)\n",
    "                   Convolution      |   |   |   |   |   |   |    * (right)\n",
    "                   layers           |   |___|   |___|   |___|    * (bottom)\n",
    "        ________                    |   (4096)  (4096)  (4096)  (4)\n",
    "       |        |                   |\n",
    "       | Current|------------------>|\n",
    "       | frame  |\n",
    "       |________|\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GoNet, self).__init__()\n",
    "        caffenet = models.alexnet(pretrained=True)\n",
    "        self.convnet = nn.Sequential(*list(caffenet.children())[:-1])\n",
    "        for param in self.convnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Linear(256*6*6*2, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(4096, 4),\n",
    "                )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.classifier.modules():\n",
    "            # fully connected layers are weight initialized with\n",
    "            # mean=0 and std=0.005 (in tracker.prototxt) and\n",
    "            # biases are set to 1\n",
    "            # tracker.prototxt link: https://goo.gl/iHGKT5\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.bias.data.fill_(1)\n",
    "                m.weight.data.normal_(0, 0.005)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.convnet(x)\n",
    "        x1 = x1.view(x.size(0), 256*6*6)\n",
    "        x2 = self.convnet(y)\n",
    "        x2 = x2.view(x.size(0), 256*6*6)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/263244/jupyter/kernel-47d5a810-f339-4156-8113-7366d0f3bd64.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "input_size = 224\n",
    "kSaveModel = 20000  # save model after every 20000 steps\n",
    "batchSize = 50  # number of samples in a batch\n",
    "kGeneratedExamplesPerImage = 10  # generate 10 synthetic samples per image\n",
    "transform = NormalizeToTensor()\n",
    "bb_params = {}\n",
    "enable_tensorboard = False\n",
    "if enable_tensorboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "args = None\n",
    "parser = argparse.ArgumentParser(description='GOTURN Training')\n",
    "num_batches=500000\n",
    "lr=1e-5\n",
    "gamma=0.1\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_decay_step=100000\n",
    "d='../data/'\n",
    "s='../saved_checkpoints/exp3/'\n",
    "lshift=5\n",
    "lscale=15\n",
    "minsc=-0.4\n",
    "maxsc=0.4\n",
    "seed=800\n",
    "resume=''\n",
    "b=50\n",
    "save_freq=20000\n",
    "\n",
    "def main():\n",
    "\n",
    "    global args, batchSize, kSaveModel, bb_params\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    batchSize = args.batch_size\n",
    "    kSaveModel = args.save_freq\n",
    "    np.random.seed(args.manual_seed)\n",
    "    torch.manual_seed(args.manual_seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(args.manual_seed)\n",
    "\n",
    "    # load bounding box motion model params\n",
    "    #bb_params['lambda_shift_frac'] = args.lambda_shift_frac\n",
    "    #bb_params['lambda_scale_frac'] = args.lambda_scale_frac\n",
    "    #bb_params['min_scale'] = args.min_scale\n",
    "    #bb_params['max_scale'] = args.max_scale\n",
    "\n",
    "    # load datasets\n",
    "    alov = ALOVDataset(os.path.join(args.data_directory,\n",
    "                       'imagedata++/'),\n",
    "                       os.path.join(args.data_directory,\n",
    "                       'alov300++_rectangleAnnotation_full/'),\n",
    "                       transform, input_size)\n",
    "    imagenet = ILSVRC2014_DET_Dataset(os.path.join(args.data_directory,\n",
    "                                      'ILSVRC2014_DET_train/'),\n",
    "                                      os.path.join(args.data_directory,\n",
    "                                      'ILSVRC2014_DET_bbox_train/'),\n",
    "                                      bb_params,\n",
    "                                      transform,\n",
    "                                      input_size)\n",
    "    # list of datasets to train on\n",
    "    datasets = [alov, imagenet]\n",
    "\n",
    "    # load model\n",
    "    net = model.GoNet().to(device)\n",
    "    # summary(net, [(3, 224, 224), (3, 224, 224)])\n",
    "    loss_fn = torch.nn.L1Loss(size_average=False).to(device)\n",
    "\n",
    "    # initialize optimizer\n",
    "    optimizer = optim.SGD(net.classifier.parameters(),\n",
    "                          lr=args.learning_rate,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "\n",
    "    if os.path.exists(args.save_directory):\n",
    "        print('Directory %s already exists' % (args.save_directory))\n",
    "    else:\n",
    "        os.makedirs(args.save_directory)\n",
    "\n",
    "    # start training\n",
    "    net = train_model(net, datasets, loss_fn, optimizer)\n",
    "\n",
    "    # save trained model\n",
    "    checkpoint = {'state_dict': net.state_dict()}\n",
    "    path = os.path.join(args.save_directory, 'pytorch_goturn.pth.tar')\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "def get_training_batch(num_running_batch, running_batch, dataset):\n",
    "    '''\n",
    "    Implements GOTURN batch formation regimen.\n",
    "    '''\n",
    "    global args, batchSize\n",
    "    done = False\n",
    "    N = kGeneratedExamplesPerImage+1\n",
    "    train_batch = None\n",
    "    x1_batch, x2_batch, y_batch = make_transformed_samples(dataset, args)\n",
    "    assert(x1_batch.shape[0] == x2_batch.shape[0] == y_batch.shape[0] == N)\n",
    "    count_in = min(batchSize - num_running_batch, N)\n",
    "    remain = N - count_in\n",
    "    running_batch['previmg'][num_running_batch:\n",
    "                             num_running_batch+count_in] = x1_batch[:count_in]\n",
    "    running_batch['currimg'][num_running_batch:\n",
    "                             num_running_batch+count_in] = x2_batch[:count_in]\n",
    "    running_batch['currbb'][num_running_batch:\n",
    "                            num_running_batch+count_in] = y_batch[:count_in]\n",
    "    num_running_batch = num_running_batch + count_in\n",
    "    if remain > 0:\n",
    "        done = True\n",
    "        train_batch = running_batch.copy()\n",
    "        running_batch['previmg'][:remain] = x1_batch[-remain:]\n",
    "        running_batch['currimg'][:remain] = x2_batch[-remain:]\n",
    "        running_batch['currbb'][:remain] = y_batch[-remain:]\n",
    "        num_running_batch = remain\n",
    "    return running_batch, train_batch, done, num_running_batch\n",
    "\n",
    "\n",
    "def make_transformed_samples(dataset, args):\n",
    "    '''\n",
    "    Given a dataset, it picks a random sample from it and returns a batch\n",
    "    of (kGeneratedExamplesPerImage+1) samples. The batch contains true sample\n",
    "    from dataset and kGeneratedExamplesPerImage samples, which are created\n",
    "    artifically with augmentation by GOTURN smooth motion model.\n",
    "    '''\n",
    "    idx = np.random.randint(dataset.len, size=1)[0]\n",
    "    # unscaled original sample (single image and bb)\n",
    "    orig_sample = dataset.get_orig_sample(idx)\n",
    "    # cropped scaled sample (two frames and bb)\n",
    "    true_sample, _ = dataset.get_sample(idx)\n",
    "    true_tensor = transform(true_sample)\n",
    "    x1_batch = torch.Tensor(kGeneratedExamplesPerImage + 1, 3,\n",
    "                            input_size, input_size)\n",
    "    x2_batch = torch.Tensor(kGeneratedExamplesPerImage + 1, 3,\n",
    "                            input_size, input_size)\n",
    "    y_batch = torch.Tensor(kGeneratedExamplesPerImage + 1, 4)\n",
    "\n",
    "    # initialize batch with the true sample\n",
    "    x1_batch[0] = true_tensor['previmg']\n",
    "    x2_batch[0] = true_tensor['currimg']\n",
    "    y_batch[0] = true_tensor['currbb']\n",
    "\n",
    "    scale = Rescale((input_size, input_size))\n",
    "    for i in range(kGeneratedExamplesPerImage):\n",
    "        sample = orig_sample\n",
    "        # unscaled current image crop with box\n",
    "        curr_sample, opts_curr = shift_crop_training_sample(sample, bb_params)\n",
    "        # unscaled previous image crop with box\n",
    "        prev_sample, opts_prev = crop_sample(sample)\n",
    "        scaled_curr_obj = scale(curr_sample, opts_curr)\n",
    "        scaled_prev_obj = scale(prev_sample, opts_prev)\n",
    "        training_sample = {'previmg': scaled_prev_obj['image'],\n",
    "                           'currimg': scaled_curr_obj['image'],\n",
    "                           'currbb': scaled_curr_obj['bb']}\n",
    "        sample = transform(training_sample)\n",
    "        x1_batch[i+1] = sample['previmg']\n",
    "        x2_batch[i+1] = sample['currimg']\n",
    "        y_batch[i+1] = sample['currbb']\n",
    "\n",
    "    return x1_batch, x2_batch, y_batch\n",
    "\n",
    "\n",
    "def train_model(model, datasets, criterion, optimizer):\n",
    "\n",
    "    global args, writer\n",
    "    since = time.time()\n",
    "    curr_loss = 0\n",
    "    lr = args.learning_rate\n",
    "    flag = False\n",
    "    start_itr = 0\n",
    "    num_running_batch = 0\n",
    "    running_batch = {'previmg': torch.Tensor(batchSize, 3, input_size, input_size),\n",
    "                     'currimg': torch.Tensor(batchSize, 3, input_size, input_size),\n",
    "                     'currbb': torch.Tensor(batchSize, 4)}\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                          step_size=args.lr_decay_step,\n",
    "                                          gamma=args.gamma)\n",
    "\n",
    "    # resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            start_itr = checkpoint['itr']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            num_running_batch = checkpoint['num_running_batch']\n",
    "            running_batch = checkpoint['running_batch']\n",
    "            lr = checkpoint['lr']\n",
    "            np.random.set_state(checkpoint['np_rand_state'])\n",
    "            torch.set_rng_state(checkpoint['torch_rand_state'])\n",
    "            print(\"=> loaded checkpoint '{}' (iteration {})\"\n",
    "                  .format(args.resume, checkpoint['itr']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    if not os.path.isdir(args.save_directory):\n",
    "        os.makedirs(args.save_directory)\n",
    "\n",
    "    itr = start_itr\n",
    "    st = time.time()\n",
    "    while itr < args.num_batches:\n",
    "\n",
    "        model.train()\n",
    "        if (args.resume and os.path.isfile(args.resume) and\n",
    "           itr == start_itr and (not flag)):\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            i = checkpoint['dataset_indx']\n",
    "            flag = True\n",
    "        else:\n",
    "            i = 0\n",
    "\n",
    "        # train on datasets\n",
    "        # usually ALOV and ImageNet\n",
    "        while i < len(datasets):\n",
    "            dataset = datasets[i]\n",
    "            i = i+1\n",
    "            (running_batch, train_batch,\n",
    "                done, num_running_batch) = get_training_batch(num_running_batch,\n",
    "                                                              running_batch,\n",
    "                                                              dataset)\n",
    "            # print(i, num_running_batch, done)\n",
    "            if done:\n",
    "                scheduler.step()\n",
    "                # load sample\n",
    "                x1 = train_batch['previmg'].to(device)\n",
    "                x2 = train_batch['currimg'].to(device)\n",
    "                y = train_batch['currbb'].requires_grad_(False).to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                output = model(x1, x2)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                # backward + optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                curr_loss = loss.item()\n",
    "                end = time.time()\n",
    "                itr = itr + 1\n",
    "                print('[training] step = %d/%d, loss = %f, time = %f'\n",
    "                      % (itr, args.num_batches, curr_loss, end-st))\n",
    "                sys.stdout.flush()\n",
    "                del(train_batch)\n",
    "                st = time.time()\n",
    "\n",
    "                if enable_tensorboard:\n",
    "                    writer.add_scalar('train/batch_loss', curr_loss, itr)\n",
    "\n",
    "                if itr > 0 and itr % kSaveModel == 0:\n",
    "                    path = os.path.join(args.save_directory,\n",
    "                                        'model_itr_' + str(itr) + '_loss_' +\n",
    "                                        str(round(curr_loss, 3)) + '.pth.tar')\n",
    "                    save_checkpoint({'itr': itr,\n",
    "                                     'np_rand_state': np.random.get_state(),\n",
    "                                     'torch_rand_state': torch.get_rng_state(),\n",
    "                                     'l1_loss': curr_loss,\n",
    "                                     'state_dict': model.state_dict(),\n",
    "                                     'optimizer': optimizer.state_dict(),\n",
    "                                     'scheduler': scheduler.state_dict(),\n",
    "                                     'num_running_batch': num_running_batch,\n",
    "                                     'running_batch': running_batch,\n",
    "                                     'lr': lr,\n",
    "                                     'dataset_indx': i}, path)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    if enable_tensorboard:\n",
    "        writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "        writer.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
